{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Foruck/sentiment-analysis-demo/blob/master/bert_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6r0ZwikpHmYO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 准备工作"
      ]
    },
    {
      "metadata": {
        "id": "fxZi1hp_GZbK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 加载数据\n",
        "\n",
        "上传\n",
        "cn_train_data.h5\n",
        "en_train_data.h5\n",
        "cn_valid_data.h5\n",
        "en_valid_data.h5\n",
        "到自己的Google Drive\n"
      ]
    },
    {
      "metadata": {
        "id": "WVGVxS45EPaQ",
        "colab_type": "code",
        "outputId": "e08c874a-04de-450a-ba1e-fb33ff86fc64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o3qrbzI6Gtuy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 配置文件目录环境\n",
        "\n",
        "log：训练日志目录\n",
        "\n",
        "bst_model：最优checkpoint\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GAygoCb1KJLS",
        "colab_type": "code",
        "outputId": "a4fb75a3-3c42-449e-a5a2-4c333ffbc8b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install psmisc\n",
        "!rm -rf log\n",
        "!rm -rf bst_model\n",
        "!mkdir log\n",
        "!mkdir bst_model\n",
        "!cp /content/gdrive/My\\ Drive/cn_train_data.h5 cn_train_data.h5\n",
        "!cp /content/gdrive/My\\ Drive/en_train_data.h5 en_train_data.h5\n",
        "!cp /content/gdrive/My\\ Drive/cn_valid_data.h5 cn_valid_data.h5\n",
        "!cp /content/gdrive/My\\ Drive/en_valid_data.h5 en_valid_data.h5\n",
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "psmisc is already the newest version (23.1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "bst_model\t  cn_valid_data.h5  en_valid_data.h5  log\n",
            "cn_train_data.h5  en_train_data.h5  gdrive\t      sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wdc5tA4dHKJX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 配置python运行环境"
      ]
    },
    {
      "metadata": {
        "id": "C4vjhWx9R0CV",
        "colab_type": "code",
        "outputId": "4d9a4759-8dba-4876-e326-4618202eb21c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        }
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall torch\n",
        "!pip uninstall torchvision\n",
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install torch torchvision\n",
        "import torch\n",
        "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
        "print('Device:', torch.device('cuda:0'))\n",
        "\n",
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torch-1.0.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/lib/python3.6/dist-packages/caffe2/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torch-1.0.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/*\n",
            "Proceed (y/n)? n\n",
            "Uninstalling torchvision-0.2.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision-0.2.1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/*\n",
            "Proceed (y/n)? n\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Torch 1.0.0 CUDA 9.0.176\n",
            "Device: cuda:0\n",
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.67)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.6)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.0.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2018.11.29)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.3)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.1.13)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.67 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.67)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.67->boto3->pytorch_pretrained_bert) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.67->boto3->pytorch_pretrained_bert) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.67->boto3->pytorch_pretrained_bert) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fnVUgQZbHeEY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 开始"
      ]
    },
    {
      "metadata": {
        "id": "u6ZxFBtmHsXd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 导入模块"
      ]
    },
    {
      "metadata": {
        "id": "1up16TvMNwHU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import datetime\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import h5py\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.autograd import Variable\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertAdam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_Cw9G6MHxI3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 模型超参数设置\n",
        "\n",
        "embedding_length\n",
        "Sentence_Max_Length\n",
        "不可改动"
      ]
    },
    {
      "metadata": {
        "id": "rPzTLw2iNxoL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LSTM_Hidden_Size = 256\n",
        "embedding_length = 768\n",
        "Sentence_Max_Length = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JmcepKJbH81_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 模型"
      ]
    },
    {
      "metadata": {
        "id": "MqvH0ISrEQi_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class bertDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, data_path):\n",
        "    with h5py.File(data_path, 'r') as f:\n",
        "      self.data = f['data'][:, :]\n",
        "      self.mask = f['mask'][:, :]\n",
        "      self.annot = f['annot'][:]\n",
        "    \n",
        "  def __len__(self):\n",
        "    return self.annot.shape[0]\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx, :], self.mask[idx, :], self.annot[idx]\n",
        "\n",
        "      \n",
        "class myBert(torch.nn.Module):\n",
        "  def __init__(self, embedding_length=768, bert_path='bert-base-uncased', window=[7], classes=2, use_cuda=True):\n",
        "    super(myBert, self).__init__()\n",
        "    self.use_cuda = use_cuda\n",
        "    self.num_filter = len(window)\n",
        "\n",
        "    # Bert model\n",
        "    self.bert = BertModel.from_pretrained(bert_path)\n",
        "\n",
        "    # Convolution layers\n",
        "    conv1, conv2, conv3, conv4 = [], [], [], []\n",
        "    for i in range(self.num_filter):\n",
        "      conv1.append(nn.Conv2d(1, 256, (window[i], embedding_length), stride=(1, 1), padding=(int((window[i] - 1) / 2), 0))) # out n*64*128*1\n",
        "      conv2.append(nn.Conv1d(256, 128, 3, stride=1, padding=1)) # out n*128*64\n",
        "      conv3.append(nn.Conv1d(128, 64, 3, stride=1, padding=1)) # out n*64*32\n",
        "      conv4.append(nn.Conv1d(64, 16, 1, stride=1, padding=0)) # out n*16*16\n",
        "    self.conv1, self.conv2 = nn.ModuleList(conv1), nn.ModuleList(conv2)\n",
        "    self.conv3, self.conv4 = nn.ModuleList(conv3), nn.ModuleList(conv4)\n",
        "    for i in range(self.num_filter):\n",
        "      init.kaiming_normal_(self.conv1[i].weight.data)\n",
        "      init.kaiming_normal_(self.conv2[i].weight.data)\n",
        "      init.kaiming_normal_(self.conv3[i].weight.data)\n",
        "      init.kaiming_normal_(self.conv4[i].weight.data)\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    # LSTM layers\n",
        "    self.lstm1 = nn.LSTMCell(embedding_length, LSTM_Hidden_Size) # out n*1*LSTM_Hidden_Size\n",
        "    self.lstm2 = nn.LSTMCell(embedding_length, LSTM_Hidden_Size)\n",
        "\n",
        "    # FC layer\n",
        "    self.fc = nn.Linear(LSTM_Hidden_Size * 2 + 256 * self.num_filter, classes)\n",
        "    init.kaiming_normal_(self.fc.weight.data)\n",
        "    self.fc.bias.data.fill_(0)\n",
        "    \n",
        "  def forward(self, inputs, mask):\n",
        "    # Get Features\n",
        "    inputs = self.bert(inputs, token_type_ids=None, attention_mask=mask, output_all_encoded_layers=False)[0]\n",
        "    inputs = inputs.unsqueeze(1)\n",
        "        \n",
        "    # Go through Bi-LSTM\n",
        "    n = inputs.shape[0]\n",
        "    x0 = inputs.squeeze(1)\n",
        "    if self.use_cuda:\n",
        "      if not inputs.is_cuda:\n",
        "        inputs = inputs.cuda()\n",
        "        x0 = x0.cuda()\n",
        "      cx1 = torch.zeros(n, LSTM_Hidden_Size).cuda()\n",
        "      hx1 = torch.zeros(n, LSTM_Hidden_Size).cuda()\n",
        "      hx2 = torch.zeros(n, LSTM_Hidden_Size).cuda()\n",
        "      cx2 = torch.zeros(n, LSTM_Hidden_Size).cuda()\n",
        "      hxs1 = torch.zeros((n, x0.shape[1], LSTM_Hidden_Size)).cuda()\n",
        "      hxs2 = torch.zeros((n, x0.shape[1], LSTM_Hidden_Size)).cuda()\n",
        "    else:\n",
        "      if inputs.is_cuda:\n",
        "        inputs = inputs.cpu()\n",
        "        x0 = x0.cpu()\n",
        "      cx1 = torch.zeros(n, LSTM_Hidden_Size)\n",
        "      hx1 = torch.zeros(n, LSTM_Hidden_Size)\n",
        "      cx2 = torch.zeros(n, LSTM_Hidden_Size)\n",
        "      hx2 = torch.zeros(n, LSTM_Hidden_Size)\n",
        "      hxs1 = torch.zeros((n, x0.shape[1], LSTM_Hidden_Size))\n",
        "      hxs2 = torch.zeros((n, x0.shape[1], LSTM_Hidden_Size))\n",
        "    \n",
        "    for i in range(x0.shape[1]):\n",
        "      hx1, cx1 = self.lstm1(x0[:, i, :], (hx1, cx1))\n",
        "      hxs1[:, i, :] = hx1\n",
        "      hx2, cx2 = self.lstm1(x0[:, x0.shape[1] - 1 - i, :], (hx2, cx2))\n",
        "      hxs2[:, i, :] = hx2\n",
        "    lstm_x = torch.cat((torch.mean(hxs1, 1, True).squeeze(1), torch.mean(hxs2, 1, True).squeeze(1)), 1)\n",
        "\n",
        "    # Go Through CNN\n",
        "    x = []\n",
        "    for i in range(self.num_filter):\n",
        "      x.append(self.conv1[i](inputs))\n",
        "      x[i] = x[i].squeeze(3)\n",
        "      x[i] = F.relu(F.max_pool1d(x[i], kernel_size=2, stride=2))\n",
        "      x[i] = self.conv2[i](x[i])\n",
        "      x[i] = F.relu(F.max_pool1d(x[i], kernel_size=2, stride=2))\n",
        "      x[i] = self.conv3[i](x[i])\n",
        "      x[i] = F.relu(F.max_pool1d(x[i], kernel_size=2, stride=2))\n",
        "      x[i] = self.conv4[i](x[i])\n",
        "      x[i] = x[i].view(n, -1)\n",
        "      x[i] = self.dropout(x[i])\n",
        "        \n",
        "    cnn_x = torch.cat(x, 1)\n",
        "    x1 = torch.cat((lstm_x, cnn_x), 1)\n",
        "    x1 = self.dropout(self.fc(x1))\n",
        "    return x1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RameSu2AIAf3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 训练与测试函数"
      ]
    },
    {
      "metadata": {
        "id": "SUqQ3pTgN_1F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, logger, epoch=0, print_every=100):\n",
        "  model = model.train()\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  all_loss, all_accuracy = 0.0, 0.0\n",
        "  hit, cnt = 0, 0\n",
        "  for i, (x, mask, target) in enumerate(train_loader):\n",
        "    x = x.cuda().long()\n",
        "    mask = mask.cuda().long()\n",
        "    target = target.cuda().long()\n",
        "    target = torch.clamp(target, min=0, max=1)\n",
        "    \n",
        "    scores = model(x, mask)\n",
        "    loss = loss_fn(scores, target)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    pred = torch.argmax(scores, dim=1)\n",
        "    hit = torch.sum(target == pred)\n",
        "    \n",
        "    accuracy = float(hit) / int(x.shape[0])\n",
        "    if i % print_every == 0:\n",
        "      logger.info('Epoch %d, Iter %d, loss=%.4f, acc=%.4f' % (epoch, i, loss, accuracy))\n",
        "      print(time.strftime(\"%Y-%m-%d %H:%M:%S \", time.localtime()) + 'Epoch %d, Iter %d, loss=%.4f, acc=%.4f' % (epoch, i, loss, accuracy))\n",
        "    all_loss += float(loss) * int(x.shape[0])\n",
        "    all_accuracy += float(hit)\n",
        "    cnt += int(x.shape[0])\n",
        "    \n",
        "  all_loss /= float(cnt)\n",
        "  all_accuracy /= float(cnt)\n",
        "  logger.info('Epoch %d, train_loss=%.4f, train_accuracy=%.4f' % (epoch, all_loss, all_accuracy))\n",
        "  print(time.strftime(\"%Y-%m-%d %H:%M:%S \", time.localtime()) + 'Epoch %d, train_loss=%.4f, train_accuracy=%.4f' % (epoch, all_loss, all_accuracy))\n",
        "  return model, optimizer\n",
        "\n",
        "def evaluate(model, valid_loader, logger, epoch=0, print_every=100):\n",
        "  model = model.eval()\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  all_loss = 0.0\n",
        "  hit, tot = 0, 0\n",
        "  for i, (x, mask, target) in enumerate(valid_loader):\n",
        "    x = x.cuda().long()\n",
        "    mask = mask.cuda().long()\n",
        "    target = target.cuda().long()\n",
        "    target = torch.clamp(target, min=0, max=1)\n",
        "    \n",
        "    scores = model(x, mask)\n",
        "    loss = loss_fn(scores, target)\n",
        "    \n",
        "    pred = torch.argmax(scores, dim=1)\n",
        "    \n",
        "    hit += float(torch.sum(target == pred))\n",
        "    all_loss += float(loss) * int(x.shape[0])\n",
        "    tot += int(x.shape[0])\n",
        "  \n",
        "  all_loss /= tot\n",
        "  accuracy = float(hit) / tot\n",
        "  logger.info('Epoch %d, valid_loss=%.4f, valid_accuracy=%.4f' % (epoch, all_loss, accuracy))\n",
        "  print(time.strftime(\"%Y-%m-%d %H:%M:%S \", time.localtime()) + 'Epoch %d, valid_loss=%.4f, valid_accuracy=%.4f' % (epoch, all_loss, accuracy))\n",
        "  return model, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dMEkaDU8IEhf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 查看显存使用状况"
      ]
    },
    {
      "metadata": {
        "id": "DZY_IjiVO4Zt",
        "colab_type": "code",
        "outputId": "6a58625c-0392-4a2f-e531-9d98cdc0a14a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Dec 21 05:54:34 2018       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P0    58W / 149W |   8552MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4iMOZxY8IHmo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 训练参数设置"
      ]
    },
    {
      "metadata": {
        "id": "hqUNGt4SOTc7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "device = torch.device(\"cuda\")\n",
        "end_epoch = 30\n",
        "tag = 'en' # en英文，cn中文\n",
        "lr = 5e-5 #可以调节\n",
        "checkpoint = ''\n",
        "bz = 64  #理论上越大就越快越好但也需要更多Epoch\n",
        "warmup_proportion = 0.1\n",
        "bst_acc = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Q6V9yWkIKi0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 数据集、模型加载"
      ]
    },
    {
      "metadata": {
        "id": "4tvUPCngPTQL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if tag == 'cn':\n",
        "  train_set = bertDataset('cn_train_data.h5')\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=bz, shuffle=True, num_workers=8)\n",
        "  valid_set = bertDataset('cn_valid_data.h5')\n",
        "  valid_loader = torch.utils.data.DataLoader(dataset=valid_set, batch_size=int(bz / 2), shuffle=True, num_workers=8)\n",
        "  myModel = myBert(embedding_length, 'bert-base-chinese', use_cuda=True)\n",
        "elif tag == 'en':\n",
        "  train_set = bertDataset('en_train_data.h5')\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=bz, shuffle=True, num_workers=8)\n",
        "  valid_set = bertDataset('en_valid_data.h5')\n",
        "  valid_loader = torch.utils.data.DataLoader(dataset=valid_set, batch_size=int(bz / 2), shuffle=True, num_workers=8)\n",
        "  myModel = myBert(embedding_length, 'bert-base-uncased', use_cuda=True)\n",
        "  \n",
        "if checkpoint != '':\n",
        "  state = torch.load(args.checkpoint)\n",
        "  myModel.load_state_dict(state['model_state'])\n",
        "  optimizer.load_state_dict(state['optim_state'])\n",
        "  epoch = state['epoch']\n",
        "  bst_acc = state['acc']\n",
        "else:\n",
        "  epoch = 0\n",
        "\n",
        "myModel = myModel.cuda()\n",
        "ignored_params = list(map(id, myModel.bert.parameters()))\n",
        "base_params = filter(lambda p: id(p) not in ignored_params, myModel.parameters())\n",
        "optimizer_grouped_parameters = [{'params': base_params, 'weight_decay': 0.01}, {'params': myModel.bert.parameters(), 'weight_decay': 0.0, 'lr': 1e-6}]\n",
        "optimizer = BertAdam(optimizer_grouped_parameters, lr=lr, warmup=warmup_proportion, t_total=train_set.__len__())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gecyiAAgIN-u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### log、checkpoint存储目录设置"
      ]
    },
    {
      "metadata": {
        "id": "7ZpYW4W1RAqs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "job_name =  '_'.join([tag, str(lr), datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')])\n",
        "save_path = 'bst_model/' + job_name + '.pth'\n",
        "log_path = 'log/' + job_name + '.log'\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(level = logging.INFO)\n",
        "handler = logging.FileHandler(log_path)\n",
        "handler.setLevel(logging.INFO)\n",
        "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "logger.addHandler(handler)\n",
        "logger.info(\"Start print log\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HKtl0HAuIT6e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 开始训练"
      ]
    },
    {
      "metadata": {
        "id": "wAX-He7RRIxE",
        "colab_type": "code",
        "outputId": "dc6b4256-1272-433b-e0f0-ecf509e827c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1703
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(epoch, end_epoch):\n",
        "  logger.info('=> Epoch %d, lr = %0.6f <=' % (i, lr))\n",
        "  myModel, optimizer = train(myModel, train_loader, optimizer, logger, epoch=i, print_every=50)\n",
        "  myModel, accuracy = evaluate(myModel, valid_loader, logger, epoch=i)\n",
        "  \n",
        "  if (accuracy > bst_acc):\n",
        "    bst_acc = accuracy\n",
        "    state = {'model_state': myModel.state_dict(), 'epoch': i, 'optim_state': optimizer.state_dict(), 'acc': bst_acc}\n",
        "    torch.save(state, save_path)\n",
        "  \n",
        "logger.info(\"Finish\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-12-21 05:54:47 Epoch 0, Iter 0, loss=0.8415, acc=0.5312\n",
            "2018-12-21 05:56:27 Epoch 0, Iter 50, loss=0.9319, acc=0.4375\n",
            "2018-12-21 05:58:07 Epoch 0, Iter 100, loss=0.8816, acc=0.3438\n",
            "2018-12-21 05:59:47 Epoch 0, Iter 150, loss=0.7814, acc=0.5625\n",
            "2018-12-21 06:01:28 Epoch 0, Iter 200, loss=0.7481, acc=0.5312\n",
            "2018-12-21 06:03:08 Epoch 0, Iter 250, loss=0.7851, acc=0.5312\n",
            "2018-12-21 06:03:59 Epoch 0, train_loss=0.7756, train_accuracy=0.5319\n",
            "2018-12-21 06:10:22 Epoch 0, valid_loss=0.4945, valid_accuracy=0.7493\n",
            "2018-12-21 06:10:32 Epoch 1, Iter 0, loss=0.5509, acc=0.6562\n",
            "2018-12-21 06:12:13 Epoch 1, Iter 50, loss=0.3652, acc=0.8438\n",
            "2018-12-21 06:13:53 Epoch 1, Iter 100, loss=0.4293, acc=0.7500\n",
            "2018-12-21 06:15:33 Epoch 1, Iter 150, loss=0.3856, acc=0.6562\n",
            "2018-12-21 06:17:12 Epoch 1, Iter 200, loss=0.5569, acc=0.7188\n",
            "2018-12-21 06:18:52 Epoch 1, Iter 250, loss=0.3915, acc=0.7188\n",
            "2018-12-21 06:19:43 Epoch 1, train_loss=0.5417, train_accuracy=0.6993\n",
            "2018-12-21 06:26:06 Epoch 1, valid_loss=0.3638, valid_accuracy=0.8343\n",
            "2018-12-21 06:26:16 Epoch 2, Iter 0, loss=0.6876, acc=0.6875\n",
            "2018-12-21 06:27:57 Epoch 2, Iter 50, loss=0.6411, acc=0.7812\n",
            "2018-12-21 06:29:37 Epoch 2, Iter 100, loss=0.4583, acc=0.7188\n",
            "2018-12-21 06:31:18 Epoch 2, Iter 150, loss=0.8402, acc=0.5625\n",
            "2018-12-21 06:32:58 Epoch 2, Iter 200, loss=0.3803, acc=0.7500\n",
            "2018-12-21 06:34:39 Epoch 2, Iter 250, loss=0.4032, acc=0.7188\n",
            "2018-12-21 06:35:30 Epoch 2, train_loss=0.4973, train_accuracy=0.7301\n",
            "2018-12-21 06:41:52 Epoch 2, valid_loss=0.2530, valid_accuracy=0.8980\n",
            "2018-12-21 06:42:03 Epoch 3, Iter 0, loss=0.5847, acc=0.6562\n",
            "2018-12-21 06:43:43 Epoch 3, Iter 50, loss=0.7593, acc=0.7188\n",
            "2018-12-21 06:45:23 Epoch 3, Iter 100, loss=0.5538, acc=0.7188\n",
            "2018-12-21 06:47:03 Epoch 3, Iter 150, loss=0.4245, acc=0.8125\n",
            "2018-12-21 06:48:43 Epoch 3, Iter 200, loss=0.3924, acc=0.6875\n",
            "2018-12-21 06:50:23 Epoch 3, Iter 250, loss=0.5830, acc=0.7500\n",
            "2018-12-21 06:51:13 Epoch 3, train_loss=0.4682, train_accuracy=0.7460\n",
            "2018-12-21 06:57:36 Epoch 3, valid_loss=0.1655, valid_accuracy=0.9470\n",
            "2018-12-21 06:57:47 Epoch 4, Iter 0, loss=0.6153, acc=0.6250\n",
            "2018-12-21 06:59:27 Epoch 4, Iter 50, loss=0.4434, acc=0.8438\n",
            "2018-12-21 07:01:06 Epoch 4, Iter 100, loss=0.5299, acc=0.7188\n",
            "2018-12-21 07:02:46 Epoch 4, Iter 150, loss=0.4805, acc=0.7812\n",
            "2018-12-21 07:04:26 Epoch 4, Iter 200, loss=0.5519, acc=0.6875\n",
            "2018-12-21 07:06:05 Epoch 4, Iter 250, loss=0.3783, acc=0.8125\n",
            "2018-12-21 07:06:56 Epoch 4, train_loss=0.4652, train_accuracy=0.7503\n",
            "2018-12-21 07:13:16 Epoch 4, valid_loss=0.0958, valid_accuracy=0.9767\n",
            "2018-12-21 07:13:27 Epoch 5, Iter 0, loss=0.5906, acc=0.8125\n",
            "2018-12-21 07:15:06 Epoch 5, Iter 50, loss=0.7239, acc=0.7188\n",
            "2018-12-21 07:16:46 Epoch 5, Iter 100, loss=0.5389, acc=0.6875\n",
            "2018-12-21 07:18:26 Epoch 5, Iter 150, loss=0.4741, acc=0.8438\n",
            "2018-12-21 07:20:05 Epoch 5, Iter 200, loss=0.4717, acc=0.6250\n",
            "2018-12-21 07:21:45 Epoch 5, Iter 250, loss=0.3703, acc=0.7812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b8b1a8a24b22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=> Epoch %d, lr = %0.6f <='\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmyModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mmyModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-29a7daf8a5ed>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, logger, epoch, print_every)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;31m# Add grad clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_grad_norm'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                     \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_grad_norm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mtotal_norm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(self, p, dim, keepdim)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fro\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;34mr\"\"\"See :func: `torch.norm`\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbtrifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out)\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrobenius_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"nuc\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fro\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "PyH2SbvbIWxI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 自行添加：/bst_model、/log内文件保存到google drive或本地"
      ]
    },
    {
      "metadata": {
        "id": "1GAoZvBEI_RN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TO DO"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}