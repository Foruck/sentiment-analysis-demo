{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Foruck/sentiment-analysis-demo/blob/attention/bert_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6r0ZwikpHmYO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 准备工作"
      ]
    },
    {
      "metadata": {
        "id": "fxZi1hp_GZbK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 加载数据\n",
        "\n",
        "上传\n",
        "cn_train_data.h5\n",
        "en_train_data.h5\n",
        "cn_valid_data.h5\n",
        "en_valid_data.h5\n",
        "到自己的Google Drive\n"
      ]
    },
    {
      "metadata": {
        "id": "WVGVxS45EPaQ",
        "colab_type": "code",
        "outputId": "ddcd29e2-c35c-425b-b120-293db3552eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o3qrbzI6Gtuy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 配置文件目录环境\n",
        "\n",
        "log：训练日志目录\n",
        "\n",
        "bst_model：最优checkpoint\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GAygoCb1KJLS",
        "colab_type": "code",
        "outputId": "7c9f33dd-62c1-4252-8f59-584112f83e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install psmisc\n",
        "!rm -rf log\n",
        "!rm -rf bst_model\n",
        "!mkdir log\n",
        "!mkdir bst_model\n",
        "!cp /content/gdrive/My\\ Drive/cn_train_data.h5 cn_train_data.h5\n",
        "!cp /content/gdrive/My\\ Drive/en_train_data.h5 en_train_data.h5\n",
        "!cp /content/gdrive/My\\ Drive/cn_valid_data.h5 cn_valid_data.h5\n",
        "!cp /content/gdrive/My\\ Drive/en_valid_data.h5 en_valid_data.h5\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 86%\r\rReading package lists... 86%\r\rReading package lists... 86%\r\rReading package lists... 86%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 96%\r\rReading package lists... 96%\r\rReading package lists... 97%\r\rReading package lists... 97%\r\rReading package lists... 97%\r\rReading package lists... 97%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "The following NEW packages will be installed:\n",
            "  psmisc\n",
            "0 upgraded, 1 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 51.5 kB of archives.\n",
            "After this operation, 254 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 psmisc amd64 23.1-1 [51.5 kB]\n",
            "Fetched 51.5 kB in 3s (19.6 kB/s)\n",
            "Selecting previously unselected package psmisc.\n",
            "(Reading database ... 110842 files and directories currently installed.)\n",
            "Preparing to unpack .../psmisc_23.1-1_amd64.deb ...\n",
            "Unpacking psmisc (23.1-1) ...\n",
            "Setting up psmisc (23.1-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "bst_model\t  cn_valid_data.h5  en_valid_data.h5  log\n",
            "cn_train_data.h5  en_train_data.h5  gdrive\t      sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wdc5tA4dHKJX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 配置python运行环境"
      ]
    },
    {
      "metadata": {
        "id": "C4vjhWx9R0CV",
        "colab_type": "code",
        "outputId": "15e9f72e-d452-4812-d5c7-3f78b979a24d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install torch torchvision\n",
        "import torch\n",
        "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
        "print('Device:', torch.device('cuda:0'))\n",
        "\n",
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mSkipping torch as it is not installed.\u001b[0m\n",
            "\u001b[33mSkipping torchvision as it is not installed.\u001b[0m\n",
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 28kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x620ee000 @  0x7f46e06b42a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 22.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 4.2MB/s \n",
            "\u001b[?25hInstalling collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torch-1.0.0 torchvision-0.2.1\n",
            "Torch 1.0.0 CUDA 9.0.176\n",
            "Device: cuda:0\n",
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/68/84de54aea460eb5b2e90bf47a429aacc1ce97ff052ec40874ea38ae2331d/pytorch_pretrained_bert-0.4.0-py3-none-any.whl (45kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.6)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.67)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2018.11.29)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.67 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.67)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.3)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.1.13)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.67->boto3->pytorch_pretrained_bert) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.67->boto3->pytorch_pretrained_bert) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.67->boto3->pytorch_pretrained_bert) (1.11.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fnVUgQZbHeEY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 开始"
      ]
    },
    {
      "metadata": {
        "id": "u6ZxFBtmHsXd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 导入模块"
      ]
    },
    {
      "metadata": {
        "id": "1up16TvMNwHU",
        "colab_type": "code",
        "outputId": "8845955c-ee06-447b-bfd4-20e94170d0bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import datetime\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import h5py\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.autograd import Variable\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertAdam"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S_Cw9G6MHxI3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 模型超参数设置\n",
        "\n",
        "embedding_length\n",
        "Sentence_Max_Length\n",
        "不可改动"
      ]
    },
    {
      "metadata": {
        "id": "rPzTLw2iNxoL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LSTM_Hidden_Size = 256\n",
        "embedding_length = 768\n",
        "Sentence_Max_Length = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JmcepKJbH81_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 模型"
      ]
    },
    {
      "metadata": {
        "id": "MqvH0ISrEQi_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class bertDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, data_path):\n",
        "    with h5py.File(data_path, 'r') as f:\n",
        "      self.data = f['data'][:, :]\n",
        "      self.mask = f['mask'][:, :]\n",
        "      self.annot = f['annot'][:]\n",
        "    \n",
        "  def __len__(self):\n",
        "    return self.annot.shape[0]\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx, :], self.mask[idx, :], self.annot[idx]\n",
        "\n",
        "      \n",
        "class myBert(torch.nn.Module):\n",
        "  def __init__(self, embedding_length=768, bert_path='bert-base-uncased', window=[7], classes=2, use_cuda=True):\n",
        "    super(myBert, self).__init__()\n",
        "    self.use_cuda = use_cuda\n",
        "    self.num_filter = len(window)\n",
        "\n",
        "    # Bert model\n",
        "    self.bert = BertModel.from_pretrained(bert_path)\n",
        "\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    # LSTM layers\n",
        "    self.lstm1 = nn.LSTMCell(embedding_length, LSTM_Hidden_Size) # out n*1*LSTM_Hidden_Size\n",
        "    self.lstm2 = nn.LSTMCell(embedding_length, LSTM_Hidden_Size)\n",
        "    \n",
        "    # Attention\n",
        "    self.h1k1 = nn.Linear(LSTM_Hidden_Size, 64)\n",
        "    self.k1e1 = nn.Linear(64, 1)\n",
        "    self.h2k2 = nn.Linear(LSTM_Hidden_Size, 64)\n",
        "    self.k2e2 = nn.Linear(64, 1)\n",
        "\n",
        "    # FC layer\n",
        "    self.fc = nn.Linear(LSTM_Hidden_Size * 2, classes)\n",
        "    init.kaiming_normal_(self.fc.weight.data)\n",
        "    self.fc.bias.data.fill_(0)\n",
        "    \n",
        "    self.simple_fc = nn.Linear(768, 2)\n",
        "    \n",
        "  def forward(self, inputs, mask):\n",
        "    # Get Features\n",
        "    inputs = self.bert(inputs, token_type_ids=None, attention_mask=mask, output_all_encoded_layers=False)[0]\n",
        "    inputs = inputs.unsqueeze(1)\n",
        "        \n",
        "    # Go through Bi-LSTM\n",
        "    n = inputs.shape[0]\n",
        "    x0 = inputs.squeeze(1)\n",
        "    if self.use_cuda:\n",
        "      if not inputs.is_cuda:\n",
        "        inputs = inputs.cuda()\n",
        "        x0 = x0.cuda()\n",
        "      cx1 = torch.zeros(n, LSTM_Hidden_Size).cuda()\n",
        "      hx1 = torch.zeros(n, LSTM_Hidden_Size).cuda()\n",
        "      hx2 = torch.zeros(n, LSTM_Hidden_Size).cuda()\n",
        "      cx2 = torch.zeros(n, LSTM_Hidden_Size).cuda()\n",
        "      hxs1 = torch.zeros((n, x0.shape[1], LSTM_Hidden_Size)).cuda()\n",
        "      hxs2 = torch.zeros((n, x0.shape[1], LSTM_Hidden_Size)).cuda()\n",
        "    else:\n",
        "      if inputs.is_cuda:\n",
        "        inputs = inputs.cpu()\n",
        "        x0 = x0.cpu()\n",
        "      cx1 = torch.zeros(n, LSTM_Hidden_Size)\n",
        "      hx1 = torch.zeros(n, LSTM_Hidden_Size)\n",
        "      cx2 = torch.zeros(n, LSTM_Hidden_Size)\n",
        "      hx2 = torch.zeros(n, LSTM_Hidden_Size)\n",
        "      hxs1 = torch.zeros((n, x0.shape[1], LSTM_Hidden_Size))\n",
        "      hxs2 = torch.zeros((n, x0.shape[1], LSTM_Hidden_Size))\n",
        "    \n",
        "    for i in range(x0.shape[1]):\n",
        "      hx1, cx1 = self.lstm1(x0[:, i, :], (hx1, cx1))\n",
        "      hxs1[:, i, :] = hx1\n",
        "      hx2, cx2 = self.lstm1(x0[:, x0.shape[1] - 1 - i, :], (hx2, cx2))\n",
        "      hxs2[:, i, :] = hx2\n",
        "      \n",
        "    k1 = self.h1k1(hxs1) # n*128*64\n",
        "    e1 = self.k1e1(k1).squeeze(2) # n*128*1 -> n*128\n",
        "    e1 = F.softmax(e1, dim=1).unsqueeze(1) # n*1*128\n",
        "    lstm1 = torch.matmul(e1, hxs1).squeeze(1)\n",
        "    k2 = self.h2k2(hxs2) # n*128*64\n",
        "    e2 = self.k2e2(k2).squeeze(2)\n",
        "    e2 = F.softmax(e2, dim=1).unsqueeze(1)\n",
        "    lstm2 = torch.matmul(e2, hxs2).squeeze(1)\n",
        "    \n",
        "    lstm_x = torch.cat((lstm1, lstm2), 1)\n",
        "    \n",
        "    x1 = self.dropout(self.fc(lstm_x))\n",
        "    return x1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RameSu2AIAf3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 训练与测试函数"
      ]
    },
    {
      "metadata": {
        "id": "SUqQ3pTgN_1F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, logger, epoch=0, print_every=100):\n",
        "  model = model.train()\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  all_loss, all_accuracy = 0.0, 0.0\n",
        "  hit, cnt = 0, 0\n",
        "  for i, (x, mask, target) in enumerate(train_loader):\n",
        "    x = x.cuda().long()\n",
        "    mask = mask.cuda().long()\n",
        "    target = target.cuda().long()\n",
        "    target = torch.clamp(target, min=0, max=1)\n",
        "    \n",
        "    scores = model(x, mask)\n",
        "    loss = loss_fn(scores, target)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    pred = torch.argmax(scores, dim=1)\n",
        "    hit = torch.sum(target == pred)\n",
        "    accuracy = float(hit) / int(x.shape[0])\n",
        "    if i % print_every == 0:\n",
        "      logger.info('Epoch %d, Iter %d, loss=%.4f, acc=%.4f' % (epoch, i, loss, accuracy))\n",
        "      print(time.strftime(\"%Y-%m-%d %H:%M:%S \", time.localtime()) + 'Epoch %d, Iter %d, loss=%.4f, acc=%.4f' % (epoch, i, loss, accuracy))\n",
        "    \n",
        "    all_loss += float(loss) * int(x.shape[0])\n",
        "    all_accuracy += float(hit)\n",
        "    cnt += int(x.shape[0])\n",
        "    \n",
        "  all_loss /= float(cnt)\n",
        "  all_accuracy /= float(cnt)\n",
        "  logger.info('Epoch %d, train_loss=%.4f, train_accuracy=%.4f' % (epoch, all_loss, all_accuracy))\n",
        "  print(time.strftime(\"%Y-%m-%d %H:%M:%S \", time.localtime()) + 'Epoch %d, train_loss=%.4f, train_accuracy=%.4f' % (epoch, all_loss, all_accuracy))\n",
        "  return model, optimizer\n",
        "\n",
        "def evaluate(model, valid_loader, logger, epoch=0, print_every=100):\n",
        "  model = model.eval()\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  all_loss = 0.0\n",
        "  hit, tot = 0, 0\n",
        "  for i, (x, mask, target) in enumerate(valid_loader):\n",
        "    x = x.cuda().long()\n",
        "    mask = mask.cuda().long()\n",
        "    target = target.cuda().long()\n",
        "    target = torch.clamp(target, min=0, max=1)\n",
        "    \n",
        "    scores = model(x, mask)\n",
        "    loss = loss_fn(scores, target)\n",
        "    pred = torch.argmax(scores, dim=1)\n",
        "    \n",
        "    hit += float(torch.sum(target == pred))\n",
        "    all_loss += float(loss) * int(x.shape[0])\n",
        "    tot += int(x.shape[0])\n",
        "  \n",
        "  all_loss /= tot\n",
        "  accuracy = float(hit) / tot\n",
        "  logger.info('Epoch %d, valid_loss=%.4f, valid_accuracy=%.4f' % (epoch, all_loss, accuracy))\n",
        "  print(time.strftime(\"%Y-%m-%d %H:%M:%S \", time.localtime()) + 'Epoch %d, valid_loss=%.4f, valid_accuracy=%.4f' % (epoch, all_loss, accuracy))\n",
        "  return model, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dMEkaDU8IEhf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 查看显存使用状况"
      ]
    },
    {
      "metadata": {
        "id": "DZY_IjiVO4Zt",
        "colab_type": "code",
        "outputId": "94496815-c407-4c45-9093-0282f8f35e1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Dec 24 02:08:23 2018       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4iMOZxY8IHmo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 训练参数设置"
      ]
    },
    {
      "metadata": {
        "id": "hqUNGt4SOTc7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "device = torch.device(\"cuda\")\n",
        "end_epoch = 60\n",
        "tag = 'cn' # en英文，cn中文\n",
        "lr = 1e-3 #可以调节\n",
        "checkpoint = ''\n",
        "fine_tune = 3e-5\n",
        "bz = 24\n",
        "warmup_proportion = 0.1\n",
        "bst_acc = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Q6V9yWkIKi0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 数据集、模型加载"
      ]
    },
    {
      "metadata": {
        "id": "4tvUPCngPTQL",
        "colab_type": "code",
        "outputId": "62ed4f74-eb84-4659-aefe-d691e3cb0199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "if tag == 'cn':\n",
        "  train_set = bertDataset('cn_train_data.h5')\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=bz, shuffle=True, num_workers=8)\n",
        "  valid_set = bertDataset('cn_valid_data.h5')\n",
        "  valid_loader = torch.utils.data.DataLoader(dataset=valid_set, batch_size=int(bz / 2), shuffle=True, num_workers=8)\n",
        "  myModel = myBert(embedding_length, 'bert-base-chinese', use_cuda=True)\n",
        "elif tag == 'en':\n",
        "  train_set = bertDataset('en_train_data.h5')\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=bz, shuffle=True, num_workers=8)\n",
        "  valid_set = bertDataset('en_valid_data.h5')\n",
        "  valid_loader = torch.utils.data.DataLoader(dataset=valid_set, batch_size=int(bz / 2), shuffle=True, num_workers=8)\n",
        "  myModel = myBert(embedding_length, 'bert-base-uncased', use_cuda=True)\n",
        "  \n",
        "if checkpoint != '':\n",
        "  state = torch.load(args.checkpoint)\n",
        "  myModel.load_state_dict(state['model_state'])\n",
        "  optimizer.load_state_dict(state['optim_state'])\n",
        "  epoch = state['epoch']\n",
        "  bst_acc = state['acc']\n",
        "else:\n",
        "  epoch = 0\n",
        "\n",
        "myModel = myModel.cuda()\n",
        "ignored_params = list(map(id, myModel.bert.parameters()))\n",
        "base_params = filter(lambda p: id(p) not in ignored_params, myModel.parameters())\n",
        "optimizer_grouped_parameters = [{'params': base_params, 'weight_decay': 0.01}, {'params': myModel.bert.parameters(), 'weight_decay': 0.0, 'lr': fine_tune}]\n",
        "optimizer = BertAdam(optimizer_grouped_parameters, lr=lr, warmup=warmup_proportion, t_total=train_set.__len__())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 382072689/382072689 [00:34<00:00, 11118233.41B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gecyiAAgIN-u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### log、checkpoint存储目录设置"
      ]
    },
    {
      "metadata": {
        "id": "7ZpYW4W1RAqs",
        "colab_type": "code",
        "outputId": "181147eb-95f9-4492-8e65-f89ebfc84259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "job_name =  '_'.join([tag, str(lr), datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')])\n",
        "save_path = 'bst_model/' + job_name + '.pth'\n",
        "log_path = 'log/' + job_name + '.log'\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(level = logging.INFO)\n",
        "handler = logging.FileHandler(log_path)\n",
        "handler.setLevel(logging.INFO)\n",
        "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "logger.addHandler(handler)\n",
        "logger.info(\"Start print log\")\n",
        "print(log_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log/cn_0.001_2018-12-24_02-09-14.log\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HKtl0HAuIT6e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 开始训练"
      ]
    },
    {
      "metadata": {
        "id": "wAX-He7RRIxE",
        "colab_type": "code",
        "outputId": "e2a1cb3c-8152-4e07-dae6-bc26418d85e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2483
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(epoch, end_epoch):\n",
        "  logger.info('=> Epoch %d, lr = %0.6f <=' % (i, lr))\n",
        "  myModel, optimizer = train(myModel, train_loader, optimizer, logger, epoch=i, print_every=50)\n",
        "  myModel, accuracy = evaluate(myModel, valid_loader, logger, epoch=i)\n",
        "  \n",
        "  if (accuracy > bst_acc):\n",
        "    bst_acc = accuracy\n",
        "    state = {'model_state': myModel.state_dict(), 'epoch': i, 'optim_state': optimizer.state_dict(), 'acc': bst_acc}\n",
        "    torch.save(state, save_path)\n",
        "  \n",
        "logger.info(\"Finish\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-12-24 02:09:16 Epoch 0, Iter 0, loss=0.7041, acc=0.5833\n",
            "2018-12-24 02:10:34 Epoch 0, Iter 50, loss=0.6408, acc=0.6667\n",
            "2018-12-24 02:11:53 Epoch 0, Iter 100, loss=0.6930, acc=0.7083\n",
            "2018-12-24 02:13:12 Epoch 0, Iter 150, loss=0.3079, acc=0.8750\n",
            "2018-12-24 02:14:31 Epoch 0, Iter 200, loss=0.4350, acc=0.7500\n",
            "2018-12-24 02:15:50 Epoch 0, Iter 250, loss=0.3904, acc=0.7917\n",
            "2018-12-24 02:17:08 Epoch 0, Iter 300, loss=0.6668, acc=0.7083\n",
            "2018-12-24 02:18:27 Epoch 0, Iter 350, loss=0.3160, acc=0.7917\n",
            "2018-12-24 02:19:46 Epoch 0, Iter 400, loss=0.4615, acc=0.9167\n",
            "2018-12-24 02:21:05 Epoch 0, Iter 450, loss=0.4611, acc=0.8333\n",
            "2018-12-24 02:22:23 Epoch 0, Iter 500, loss=0.3786, acc=0.7917\n",
            "2018-12-24 02:23:42 Epoch 0, Iter 550, loss=0.2627, acc=0.7500\n",
            "2018-12-24 02:25:01 Epoch 0, Iter 600, loss=0.4843, acc=0.7500\n",
            "2018-12-24 02:26:20 Epoch 0, Iter 650, loss=0.3533, acc=0.7083\n",
            "2018-12-24 02:27:38 Epoch 0, Iter 700, loss=0.3316, acc=0.8333\n",
            "2018-12-24 02:28:57 Epoch 0, Iter 750, loss=0.3055, acc=0.8333\n",
            "2018-12-24 02:30:16 Epoch 0, Iter 800, loss=0.3583, acc=0.7917\n",
            "2018-12-24 02:31:34 Epoch 0, Iter 850, loss=0.4218, acc=0.9167\n",
            "2018-12-24 02:32:53 Epoch 0, Iter 900, loss=0.5371, acc=0.7083\n",
            "2018-12-24 02:34:12 Epoch 0, Iter 950, loss=0.4911, acc=0.6250\n",
            "2018-12-24 02:34:14 Epoch 0, train_loss=0.4797, train_accuracy=0.7548\n",
            "2018-12-24 02:38:51 Epoch 0, valid_loss=0.3291, valid_accuracy=0.8625\n",
            "2018-12-24 02:39:01 Epoch 1, Iter 0, loss=0.6290, acc=0.7083\n",
            "2018-12-24 02:40:19 Epoch 1, Iter 50, loss=0.3494, acc=0.7083\n",
            "2018-12-24 02:41:38 Epoch 1, Iter 100, loss=0.3116, acc=0.8333\n",
            "2018-12-24 02:42:57 Epoch 1, Iter 150, loss=0.3936, acc=0.8750\n",
            "2018-12-24 02:44:16 Epoch 1, Iter 200, loss=0.4452, acc=0.9167\n",
            "2018-12-24 02:45:35 Epoch 1, Iter 250, loss=0.2823, acc=0.9583\n",
            "2018-12-24 02:46:53 Epoch 1, Iter 300, loss=0.4556, acc=0.7917\n",
            "2018-12-24 02:48:12 Epoch 1, Iter 350, loss=0.3838, acc=0.8333\n",
            "2018-12-24 02:49:31 Epoch 1, Iter 400, loss=0.3933, acc=0.8333\n",
            "2018-12-24 02:50:50 Epoch 1, Iter 450, loss=0.3467, acc=0.8333\n",
            "2018-12-24 02:52:08 Epoch 1, Iter 500, loss=0.4627, acc=0.8333\n",
            "2018-12-24 02:53:27 Epoch 1, Iter 550, loss=0.5957, acc=0.7083\n",
            "2018-12-24 02:54:46 Epoch 1, Iter 600, loss=0.4243, acc=0.7917\n",
            "2018-12-24 02:56:05 Epoch 1, Iter 650, loss=0.3285, acc=0.8750\n",
            "2018-12-24 02:57:23 Epoch 1, Iter 700, loss=0.4499, acc=0.7917\n",
            "2018-12-24 02:58:42 Epoch 1, Iter 750, loss=0.2561, acc=0.7917\n",
            "2018-12-24 03:00:01 Epoch 1, Iter 800, loss=0.3502, acc=0.8333\n",
            "2018-12-24 03:01:19 Epoch 1, Iter 850, loss=0.2832, acc=0.7917\n",
            "2018-12-24 03:02:38 Epoch 1, Iter 900, loss=0.3615, acc=0.7083\n",
            "2018-12-24 03:03:57 Epoch 1, Iter 950, loss=0.4975, acc=0.7500\n",
            "2018-12-24 03:04:00 Epoch 1, train_loss=0.4138, train_accuracy=0.7966\n",
            "2018-12-24 03:08:37 Epoch 1, valid_loss=0.3122, valid_accuracy=0.8773\n",
            "2018-12-24 03:08:46 Epoch 2, Iter 0, loss=0.3110, acc=0.9167\n",
            "2018-12-24 03:10:05 Epoch 2, Iter 50, loss=0.3833, acc=0.7917\n",
            "2018-12-24 03:11:24 Epoch 2, Iter 100, loss=0.3335, acc=0.8333\n",
            "2018-12-24 03:12:43 Epoch 2, Iter 150, loss=0.3734, acc=0.7917\n",
            "2018-12-24 03:14:01 Epoch 2, Iter 200, loss=0.3777, acc=0.7917\n",
            "2018-12-24 03:15:20 Epoch 2, Iter 250, loss=0.6020, acc=0.6667\n",
            "2018-12-24 03:16:39 Epoch 2, Iter 300, loss=0.3239, acc=0.9167\n",
            "2018-12-24 03:17:58 Epoch 2, Iter 350, loss=0.2792, acc=0.9583\n",
            "2018-12-24 03:19:17 Epoch 2, Iter 400, loss=0.2933, acc=0.7500\n",
            "2018-12-24 03:20:35 Epoch 2, Iter 450, loss=0.4046, acc=0.7500\n",
            "2018-12-24 03:21:54 Epoch 2, Iter 500, loss=0.2748, acc=0.7500\n",
            "2018-12-24 03:23:13 Epoch 2, Iter 550, loss=0.3608, acc=0.7917\n",
            "2018-12-24 03:24:32 Epoch 2, Iter 600, loss=0.3000, acc=0.8750\n",
            "2018-12-24 03:25:51 Epoch 2, Iter 650, loss=0.4556, acc=0.7917\n",
            "2018-12-24 03:27:09 Epoch 2, Iter 700, loss=0.2857, acc=0.7917\n",
            "2018-12-24 03:28:28 Epoch 2, Iter 750, loss=0.3794, acc=0.8333\n",
            "2018-12-24 03:29:47 Epoch 2, Iter 800, loss=0.4039, acc=0.7500\n",
            "2018-12-24 03:31:05 Epoch 2, Iter 850, loss=0.2029, acc=1.0000\n",
            "2018-12-24 03:32:24 Epoch 2, Iter 900, loss=0.4415, acc=0.7083\n",
            "2018-12-24 03:33:43 Epoch 2, Iter 950, loss=0.3290, acc=0.8333\n",
            "2018-12-24 03:33:46 Epoch 2, train_loss=0.3856, train_accuracy=0.8052\n",
            "2018-12-24 03:38:22 Epoch 2, valid_loss=0.3143, valid_accuracy=0.8766\n",
            "2018-12-24 03:38:24 Epoch 3, Iter 0, loss=0.3094, acc=0.8750\n",
            "2018-12-24 03:39:42 Epoch 3, Iter 50, loss=0.5853, acc=0.7083\n",
            "2018-12-24 03:41:01 Epoch 3, Iter 100, loss=0.3359, acc=0.7500\n",
            "2018-12-24 03:42:20 Epoch 3, Iter 150, loss=0.1869, acc=0.9167\n",
            "2018-12-24 03:43:38 Epoch 3, Iter 200, loss=0.2435, acc=0.9167\n",
            "2018-12-24 03:44:57 Epoch 3, Iter 250, loss=0.6095, acc=0.8333\n",
            "2018-12-24 03:46:16 Epoch 3, Iter 300, loss=0.2099, acc=0.8750\n",
            "2018-12-24 03:47:35 Epoch 3, Iter 350, loss=0.2932, acc=0.9583\n",
            "2018-12-24 03:48:53 Epoch 3, Iter 400, loss=0.4206, acc=0.7917\n",
            "2018-12-24 03:50:12 Epoch 3, Iter 450, loss=0.2859, acc=0.8750\n",
            "2018-12-24 03:51:31 Epoch 3, Iter 500, loss=0.2269, acc=0.8333\n",
            "2018-12-24 03:52:49 Epoch 3, Iter 550, loss=0.5185, acc=0.7500\n",
            "2018-12-24 03:54:08 Epoch 3, Iter 600, loss=0.3443, acc=0.7917\n",
            "2018-12-24 03:55:27 Epoch 3, Iter 650, loss=0.3836, acc=0.7500\n",
            "2018-12-24 03:56:46 Epoch 3, Iter 700, loss=0.3735, acc=0.7917\n",
            "2018-12-24 03:58:04 Epoch 3, Iter 750, loss=0.6038, acc=0.7917\n",
            "2018-12-24 03:59:23 Epoch 3, Iter 800, loss=0.4101, acc=0.9167\n",
            "2018-12-24 04:00:42 Epoch 3, Iter 850, loss=0.4006, acc=0.7083\n",
            "2018-12-24 04:02:00 Epoch 3, Iter 900, loss=0.6218, acc=0.6250\n",
            "2018-12-24 04:03:19 Epoch 3, Iter 950, loss=0.3595, acc=0.8333\n",
            "2018-12-24 04:03:22 Epoch 3, train_loss=0.3631, train_accuracy=0.8179\n",
            "2018-12-24 04:07:59 Epoch 3, valid_loss=0.3188, valid_accuracy=0.8840\n",
            "2018-12-24 04:08:08 Epoch 4, Iter 0, loss=0.2844, acc=0.9583\n",
            "2018-12-24 04:09:27 Epoch 4, Iter 50, loss=0.1991, acc=0.9167\n",
            "2018-12-24 04:10:46 Epoch 4, Iter 100, loss=0.3348, acc=0.7500\n",
            "2018-12-24 04:12:04 Epoch 4, Iter 150, loss=0.1899, acc=0.9167\n",
            "2018-12-24 04:13:23 Epoch 4, Iter 200, loss=0.2926, acc=0.9583\n",
            "2018-12-24 04:14:42 Epoch 4, Iter 250, loss=0.2273, acc=0.9167\n",
            "2018-12-24 04:16:01 Epoch 4, Iter 300, loss=0.3687, acc=0.7500\n",
            "2018-12-24 04:17:20 Epoch 4, Iter 350, loss=0.2195, acc=0.8333\n",
            "2018-12-24 04:18:38 Epoch 4, Iter 400, loss=0.2952, acc=0.8333\n",
            "2018-12-24 04:19:57 Epoch 4, Iter 450, loss=0.3464, acc=0.8750\n",
            "2018-12-24 04:21:16 Epoch 4, Iter 500, loss=0.1435, acc=0.9167\n",
            "2018-12-24 04:22:35 Epoch 4, Iter 550, loss=0.5379, acc=0.8333\n",
            "2018-12-24 04:23:54 Epoch 4, Iter 600, loss=0.2687, acc=0.9167\n",
            "2018-12-24 04:25:12 Epoch 4, Iter 650, loss=0.3886, acc=0.8333\n",
            "2018-12-24 04:26:31 Epoch 4, Iter 700, loss=0.2389, acc=0.8750\n",
            "2018-12-24 04:27:50 Epoch 4, Iter 750, loss=0.3916, acc=0.7500\n",
            "2018-12-24 04:29:09 Epoch 4, Iter 800, loss=0.3443, acc=0.8750\n",
            "2018-12-24 04:30:28 Epoch 4, Iter 850, loss=0.2808, acc=0.8333\n",
            "2018-12-24 04:31:47 Epoch 4, Iter 900, loss=0.1895, acc=0.8750\n",
            "2018-12-24 04:33:05 Epoch 4, Iter 950, loss=0.3983, acc=0.6250\n",
            "2018-12-24 04:33:08 Epoch 4, train_loss=0.3256, train_accuracy=0.8346\n",
            "2018-12-24 04:37:46 Epoch 4, valid_loss=0.3126, valid_accuracy=0.8822\n",
            "2018-12-24 04:37:48 Epoch 5, Iter 0, loss=0.3439, acc=0.7917\n",
            "2018-12-24 04:39:06 Epoch 5, Iter 50, loss=0.2183, acc=1.0000\n",
            "2018-12-24 04:40:25 Epoch 5, Iter 100, loss=0.2959, acc=0.8333\n",
            "2018-12-24 04:41:44 Epoch 5, Iter 150, loss=0.2962, acc=0.8333\n",
            "2018-12-24 04:43:03 Epoch 5, Iter 200, loss=0.3982, acc=0.7500\n",
            "2018-12-24 04:44:22 Epoch 5, Iter 250, loss=0.3121, acc=0.8750\n",
            "2018-12-24 04:45:41 Epoch 5, Iter 300, loss=0.1685, acc=0.9583\n",
            "2018-12-24 04:47:00 Epoch 5, Iter 350, loss=0.3391, acc=0.7083\n",
            "2018-12-24 04:48:18 Epoch 5, Iter 400, loss=0.2443, acc=0.8333\n",
            "2018-12-24 04:49:37 Epoch 5, Iter 450, loss=0.3049, acc=0.7917\n",
            "2018-12-24 04:50:56 Epoch 5, Iter 500, loss=0.2233, acc=0.8750\n",
            "2018-12-24 04:52:15 Epoch 5, Iter 550, loss=0.1721, acc=0.9167\n",
            "2018-12-24 04:53:34 Epoch 5, Iter 600, loss=0.2857, acc=0.7917\n",
            "2018-12-24 04:54:53 Epoch 5, Iter 650, loss=0.1770, acc=0.9167\n",
            "2018-12-24 04:56:12 Epoch 5, Iter 700, loss=0.3530, acc=0.7500\n",
            "2018-12-24 04:57:31 Epoch 5, Iter 750, loss=0.3422, acc=0.7917\n",
            "2018-12-24 04:58:50 Epoch 5, Iter 800, loss=0.3161, acc=0.9167\n",
            "2018-12-24 05:00:09 Epoch 5, Iter 850, loss=0.2155, acc=0.8750\n",
            "2018-12-24 05:01:27 Epoch 5, Iter 900, loss=0.2082, acc=0.9167\n",
            "2018-12-24 05:02:46 Epoch 5, Iter 950, loss=0.1447, acc=0.9583\n",
            "2018-12-24 05:02:49 Epoch 5, train_loss=0.3024, train_accuracy=0.8443\n",
            "2018-12-24 05:07:28 Epoch 5, valid_loss=0.3379, valid_accuracy=0.8800\n",
            "2018-12-24 05:07:30 Epoch 6, Iter 0, loss=0.3608, acc=0.8333\n",
            "2018-12-24 05:08:48 Epoch 6, Iter 50, loss=0.3446, acc=0.7917\n",
            "2018-12-24 05:10:07 Epoch 6, Iter 100, loss=0.3005, acc=0.8750\n",
            "2018-12-24 05:11:26 Epoch 6, Iter 150, loss=0.2579, acc=0.7083\n",
            "2018-12-24 05:12:45 Epoch 6, Iter 200, loss=0.3239, acc=0.7917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PyH2SbvbIWxI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 自行添加：/bst_model、/log内文件保存到google drive或本地\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1GAoZvBEI_RN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TO DO\n",
        "# !cp bst_model/en_5e-05_2018-12-23_04-48-53.pth gdrive/My\\ Drive/en_5e-05_2018-12-23_04-48-53.pth\n",
        "!cp bst_model/cn_0.001_2018-12-24_02-09-14.pth gdrive/My\\ Drive/cn_0.001_2018-12-24_02-09-14.pth"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}