{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "6r0ZwikpHmYO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Foruck/sentiment-analysis-demo/blob/attention/bert_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6r0ZwikpHmYO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 准备工作"
      ]
    },
    {
      "metadata": {
        "id": "fxZi1hp_GZbK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 加载数据\n",
        "\n",
        "上传\n",
        "cn_train_data.h5\n",
        "en_train_data.h5\n",
        "cn_valid_data.h5\n",
        "en_valid_data.h5\n",
        "到自己的Google Drive\n"
      ]
    },
    {
      "metadata": {
        "id": "WVGVxS45EPaQ",
        "colab_type": "code",
        "outputId": "21050bc3-e181-4436-dee6-23efb8b1198e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o3qrbzI6Gtuy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 配置文件目录环境\n",
        "\n",
        "log：训练日志目录\n",
        "\n",
        "bst_model：最优checkpoint\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GAygoCb1KJLS",
        "colab_type": "code",
        "outputId": "3ec38718-9b70-4a22-9415-613036c71f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install psmisc\n",
        "!rm -rf log\n",
        "!rm -rf bst_model\n",
        "!mkdir log\n",
        "!mkdir bst_model\n",
        "!cp /content/gdrive/My\\ Drive/cn_train_data.h5 cn_train_data.h5\n",
        "!cp /content/gdrive/My\\ Drive/en_train_data.h5 en_train_data.h5\n",
        "!cp /content/gdrive/My\\ Drive/cn_valid_data.h5 cn_valid_data.h5\n",
        "!cp /content/gdrive/My\\ Drive/en_valid_data.h5 en_valid_data.h5\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "psmisc is already the newest version (23.1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "bst_model\t  cn_valid_data.h5  en_valid_data.h5  log\n",
            "cn_train_data.h5  en_train_data.h5  gdrive\t      sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wdc5tA4dHKJX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 配置python运行环境"
      ]
    },
    {
      "metadata": {
        "id": "C4vjhWx9R0CV",
        "colab_type": "code",
        "outputId": "2809b732-de1e-454f-acab-73209da76b91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        }
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall torch\n",
        "!pip uninstall torchvision\n",
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install torch torchvision\n",
        "import torch\n",
        "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
        "print('Device:', torch.device('cuda:0'))\n",
        "\n",
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torch-1.0.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/lib/python3.6/dist-packages/caffe2/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torch-1.0.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/*\n",
            "Proceed (y/n)? n\n",
            "Uninstalling torchvision-0.2.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision-0.2.1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/*\n",
            "Proceed (y/n)? n\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Torch 1.0.0 CUDA 9.0.176\n",
            "Device: cuda:0\n",
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.67)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.18.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.6)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.1.13)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.3)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.67 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.67)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2018.11.29)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.67->boto3->pytorch_pretrained_bert) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.67->boto3->pytorch_pretrained_bert) (0.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.67->boto3->pytorch_pretrained_bert) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fnVUgQZbHeEY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 开始"
      ]
    },
    {
      "metadata": {
        "id": "u6ZxFBtmHsXd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 导入模块"
      ]
    },
    {
      "metadata": {
        "id": "1up16TvMNwHU",
        "colab_type": "code",
        "outputId": "d65a965f-0d3d-4a99-9e61-97604bd5ec8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import datetime\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import h5py\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.autograd import Variable\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertAdam"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S_Cw9G6MHxI3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 模型超参数设置\n",
        "\n",
        "embedding_length\n",
        "Sentence_Max_Length\n",
        "不可改动"
      ]
    },
    {
      "metadata": {
        "id": "rPzTLw2iNxoL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LSTM_Hidden_Size = 256\n",
        "embedding_length = 768\n",
        "Sentence_Max_Length = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JmcepKJbH81_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 模型"
      ]
    },
    {
      "metadata": {
        "id": "MqvH0ISrEQi_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class bertDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, data_path):\n",
        "    with h5py.File(data_path, 'r') as f:\n",
        "      self.data = f['data'][:, :]\n",
        "      self.mask = f['mask'][:, :]\n",
        "      self.annot = f['annot'][:]\n",
        "    \n",
        "  def __len__(self):\n",
        "    return self.annot.shape[0]\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx, :], self.mask[idx, :], self.annot[idx]\n",
        "\n",
        "      \n",
        "class myBert(torch.nn.Module):\n",
        "  def __init__(self, embedding_length=768, bert_path='bert-base-uncased', window=[7], classes=2, use_cuda=True):\n",
        "    super(myBert, self).__init__()\n",
        "    self.use_cuda = use_cuda\n",
        "    self.num_filter = len(window)\n",
        "\n",
        "    # Bert model\n",
        "    self.bert = BertModel.from_pretrained(bert_path)\n",
        "\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    # LSTM layers\n",
        "    self.lstm1 = nn.LSTMCell(embedding_length, LSTM_Hidden_Size) # out n*1*LSTM_Hidden_Size\n",
        "    self.lstm2 = nn.LSTMCell(embedding_length, LSTM_Hidden_Size)\n",
        "    \n",
        "    # Attention\n",
        "    self.h1k1 = nn.Linear(LSTM_Hidden_Size, 64)\n",
        "    self.k1e1 = nn.Linear(64, 1)\n",
        "    self.h2k2 = nn.Linear(LSTM_Hidden_Size, 64)\n",
        "    self.k2e2 = nn.Linear(64, 1)\n",
        "\n",
        "    # FC layer\n",
        "    self.fc = nn.Linear(LSTM_Hidden_Size * 2, classes)\n",
        "    init.kaiming_normal_(self.fc.weight.data)\n",
        "    self.fc.bias.data.fill_(0)\n",
        "    \n",
        "  def forward(self, inputs, mask):\n",
        "    # Get Features\n",
        "    inputs = self.bert(inputs, token_type_ids=None, attention_mask=mask, output_all_encoded_layers=False)[0]\n",
        "    inputs = inputs.unsqueeze(1)\n",
        "        \n",
        "    # Go through Bi-LSTM\n",
        "    n = inputs.shape[0]\n",
        "    x0 = inputs.squeeze(1)\n",
        "    if self.use_cuda:\n",
        "      if not inputs.is_cuda:\n",
        "        inputs = inputs.cuda()\n",
        "        x0 = x0.cuda()\n",
        "      cx1 = torch.zeros(n, LSTM_Hidden_Size).cuda()\n",
        "      hx1 = torch.zeros(n, LSTM_Hidden_Size).cuda()\n",
        "      hx2 = torch.zeros(n, LSTM_Hidden_Size).cuda()\n",
        "      cx2 = torch.zeros(n, LSTM_Hidden_Size).cuda()\n",
        "      hxs1 = torch.zeros((n, x0.shape[1], LSTM_Hidden_Size)).cuda()\n",
        "      hxs2 = torch.zeros((n, x0.shape[1], LSTM_Hidden_Size)).cuda()\n",
        "    else:\n",
        "      if inputs.is_cuda:\n",
        "        inputs = inputs.cpu()\n",
        "        x0 = x0.cpu()\n",
        "      cx1 = torch.zeros(n, LSTM_Hidden_Size)\n",
        "      hx1 = torch.zeros(n, LSTM_Hidden_Size)\n",
        "      cx2 = torch.zeros(n, LSTM_Hidden_Size)\n",
        "      hx2 = torch.zeros(n, LSTM_Hidden_Size)\n",
        "      hxs1 = torch.zeros((n, x0.shape[1], LSTM_Hidden_Size))\n",
        "      hxs2 = torch.zeros((n, x0.shape[1], LSTM_Hidden_Size))\n",
        "    \n",
        "    for i in range(x0.shape[1]):\n",
        "      hx1, cx1 = self.lstm1(x0[:, i, :], (hx1, cx1))\n",
        "      hxs1[:, i, :] = hx1\n",
        "      hx2, cx2 = self.lstm1(x0[:, x0.shape[1] - 1 - i, :], (hx2, cx2))\n",
        "      hxs2[:, i, :] = hx2\n",
        "      \n",
        "    k1 = self.h1k1(hxs1) # n*128*64\n",
        "    e1 = self.k1e1(k1).squeeze(2) # n*128*1 -> n*128\n",
        "    e1 = F.softmax(e1).unsqueeze(1) # n*1*128\n",
        "    lstm1 = torch.matmul(e1, hxs1).squeeze(1)\n",
        "    k2 = self.h2k2(hxs2) # n*128*64\n",
        "    e2 = self.k2e2(k2).squeeze(2)\n",
        "    e2 = F.softmax(e2).unsqueeze(1)\n",
        "    lstm2 = torch.matmul(e2, hxs2).squeeze(1)\n",
        "    \n",
        "    lstm_x = torch.cat((lstm1, lstm2), 1)\n",
        "    \n",
        "    x1 = self.dropout(self.fc(lstm_x))\n",
        "    return x1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RameSu2AIAf3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 训练与测试函数"
      ]
    },
    {
      "metadata": {
        "id": "SUqQ3pTgN_1F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, logger, epoch=0, print_every=100):\n",
        "  model = model.train()\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  all_loss, all_accuracy = 0.0, 0.0\n",
        "  hit, cnt = 0, 0\n",
        "  for i, (x, mask, target) in enumerate(train_loader):\n",
        "    x = x.cuda().long()\n",
        "    mask = mask.cuda().long()\n",
        "    target = target.cuda().long()\n",
        "    target = torch.clamp(target, min=0, max=1)\n",
        "    \n",
        "    scores = model(x, mask)\n",
        "    loss = loss_fn(scores, target)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    pred = torch.argmax(scores, dim=1)\n",
        "    hit = torch.sum(target == pred)\n",
        "    accuracy = float(hit) / int(x.shape[0])\n",
        "    if i % print_every == 0:\n",
        "      logger.info('Epoch %d, Iter %d, loss=%.4f, acc=%.4f' % (epoch, i, loss, accuracy))\n",
        "      print(time.strftime(\"%Y-%m-%d %H:%M:%S \", time.localtime()) + 'Epoch %d, Iter %d, loss=%.4f, acc=%.4f' % (epoch, i, loss, accuracy))\n",
        "    \n",
        "    all_loss += float(loss) * int(x.shape[0])\n",
        "    all_accuracy += float(hit)\n",
        "    cnt += int(x.shape[0])\n",
        "    \n",
        "  all_loss /= float(cnt)\n",
        "  all_accuracy /= float(cnt)\n",
        "  logger.info('Epoch %d, train_loss=%.4f, train_accuracy=%.4f' % (epoch, all_loss, all_accuracy))\n",
        "  print(time.strftime(\"%Y-%m-%d %H:%M:%S \", time.localtime()) + 'Epoch %d, train_loss=%.4f, train_accuracy=%.4f' % (epoch, all_loss, all_accuracy))\n",
        "  return model, optimizer\n",
        "\n",
        "def evaluate(model, valid_loader, logger, epoch=0, print_every=100):\n",
        "  model = model.eval()\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  all_loss = 0.0\n",
        "  hit, tot = 0, 0\n",
        "  for i, (x, mask, target) in enumerate(valid_loader):\n",
        "    x = x.cuda().long()\n",
        "    mask = mask.cuda().long()\n",
        "    target = target.cuda().long()\n",
        "    target = torch.clamp(target, min=0, max=1)\n",
        "    \n",
        "    scores = model(x, mask)\n",
        "    loss = loss_fn(scores, target)\n",
        "    pred = torch.argmax(scores, dim=1)\n",
        "    \n",
        "    hit += float(torch.sum(target == pred))\n",
        "    all_loss += float(loss) * int(x.shape[0])\n",
        "    tot += int(x.shape[0])\n",
        "  \n",
        "  all_loss /= tot\n",
        "  accuracy = float(hit) / tot\n",
        "  logger.info('Epoch %d, valid_loss=%.4f, valid_accuracy=%.4f' % (epoch, all_loss, accuracy))\n",
        "  print(time.strftime(\"%Y-%m-%d %H:%M:%S \", time.localtime()) + 'Epoch %d, valid_loss=%.4f, valid_accuracy=%.4f' % (epoch, all_loss, accuracy))\n",
        "  return model, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dMEkaDU8IEhf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 查看显存使用状况"
      ]
    },
    {
      "metadata": {
        "id": "DZY_IjiVO4Zt",
        "colab_type": "code",
        "outputId": "ec6dcb61-b56c-415d-f9bc-22502e03b9f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Dec 21 11:33:22 2018       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P0    68W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4iMOZxY8IHmo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 训练参数设置"
      ]
    },
    {
      "metadata": {
        "id": "hqUNGt4SOTc7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "device = torch.device(\"cuda\")\n",
        "end_epoch = 30\n",
        "tag = 'en' # en英文，cn中文\n",
        "lr = 1e-3 #可以调节\n",
        "checkpoint = ''\n",
        "bz = 24\n",
        "warmup_proportion = 0.1\n",
        "bst_acc = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Q6V9yWkIKi0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 数据集、模型加载"
      ]
    },
    {
      "metadata": {
        "id": "4tvUPCngPTQL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if tag == 'cn':\n",
        "  train_set = bertDataset('cn_train_data.h5')\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=bz, shuffle=True, num_workers=8)\n",
        "  valid_set = bertDataset('cn_valid_data.h5')\n",
        "  valid_loader = torch.utils.data.DataLoader(dataset=valid_set, batch_size=int(bz / 2), shuffle=True, num_workers=8)\n",
        "  myModel = myBert(embedding_length, 'bert-base-chinese', use_cuda=True)\n",
        "elif tag == 'en':\n",
        "  train_set = bertDataset('en_train_data.h5')\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=bz, shuffle=True, num_workers=8)\n",
        "  valid_set = bertDataset('en_valid_data.h5')\n",
        "  valid_loader = torch.utils.data.DataLoader(dataset=valid_set, batch_size=int(bz / 2), shuffle=True, num_workers=8)\n",
        "  myModel = myBert(embedding_length, 'bert-base-uncased', use_cuda=True)\n",
        "  \n",
        "if checkpoint != '':\n",
        "  state = torch.load(args.checkpoint)\n",
        "  myModel.load_state_dict(state['model_state'])\n",
        "  optimizer.load_state_dict(state['optim_state'])\n",
        "  epoch = state['epoch']\n",
        "  bst_acc = state['acc']\n",
        "else:\n",
        "  epoch = 0\n",
        "\n",
        "myModel = myModel.cuda()\n",
        "ignored_params = list(map(id, myModel.bert.parameters()))\n",
        "base_params = filter(lambda p: id(p) not in ignored_params, myModel.parameters())\n",
        "optimizer_grouped_parameters = [{'params': base_params, 'weight_decay': 0.01}, {'params': myModel.bert.parameters(), 'weight_decay': 0.0, 'lr': 3e-5}]\n",
        "optimizer = BertAdam(optimizer_grouped_parameters, lr=lr, warmup=warmup_proportion, t_total=train_set.__len__())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gecyiAAgIN-u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### log、checkpoint存储目录设置"
      ]
    },
    {
      "metadata": {
        "id": "7ZpYW4W1RAqs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "job_name =  '_'.join([tag, str(lr), datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')])\n",
        "save_path = 'bst_model/' + job_name + '.pth'\n",
        "log_path = 'log/' + job_name + '.log'\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(level = logging.INFO)\n",
        "handler = logging.FileHandler(log_path)\n",
        "handler.setLevel(logging.INFO)\n",
        "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "logger.addHandler(handler)\n",
        "logger.info(\"Start print log\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HKtl0HAuIT6e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 开始训练"
      ]
    },
    {
      "metadata": {
        "id": "wAX-He7RRIxE",
        "colab_type": "code",
        "outputId": "5eab4c01-6ca3-4474-f91d-d51ce8e05593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1439
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(epoch, end_epoch):\n",
        "  logger.info('=> Epoch %d, lr = %0.6f <=' % (i, lr))\n",
        "  myModel, optimizer = train(myModel, train_loader, optimizer, logger, epoch=i, print_every=50)\n",
        "  myModel, accuracy = evaluate(myModel, valid_loader, logger, epoch=i)\n",
        "  \n",
        "  if (accuracy > bst_acc):\n",
        "    bst_acc = accuracy\n",
        "    state = {'model_state': myModel.state_dict(), 'epoch': i, 'optim_state': optimizer.state_dict(), 'acc': bst_acc}\n",
        "    torch.save(state, save_path)\n",
        "  \n",
        "logger.info(\"Finish\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-12-21 11:33:37 Epoch 0, Iter 0, loss=1.8241, acc=0.5000\n",
            "2018-12-21 11:34:57 Epoch 0, Iter 50, loss=0.7922, acc=0.5833\n",
            "2018-12-21 11:36:18 Epoch 0, Iter 100, loss=0.4415, acc=0.7500\n",
            "2018-12-21 11:37:39 Epoch 0, Iter 150, loss=0.6352, acc=0.6667\n",
            "2018-12-21 11:38:59 Epoch 0, Iter 200, loss=0.7279, acc=0.6667\n",
            "2018-12-21 11:40:20 Epoch 0, Iter 250, loss=0.4562, acc=0.7917\n",
            "2018-12-21 11:41:41 Epoch 0, Iter 300, loss=0.5325, acc=0.6667\n",
            "2018-12-21 11:43:01 Epoch 0, Iter 350, loss=0.4433, acc=0.7500\n",
            "2018-12-21 11:43:30 Epoch 0, train_loss=0.5942, train_accuracy=0.6719\n",
            "2018-12-21 11:45:22 Epoch 0, valid_loss=0.3968, valid_accuracy=0.8341\n",
            "2018-12-21 11:45:32 Epoch 1, Iter 0, loss=0.7261, acc=0.7083\n",
            "2018-12-21 11:46:53 Epoch 1, Iter 50, loss=0.3520, acc=0.7917\n",
            "2018-12-21 11:48:14 Epoch 1, Iter 100, loss=0.1816, acc=0.8333\n",
            "2018-12-21 11:49:35 Epoch 1, Iter 150, loss=0.3821, acc=0.7083\n",
            "2018-12-21 11:50:56 Epoch 1, Iter 200, loss=0.4741, acc=0.7083\n",
            "2018-12-21 11:52:17 Epoch 1, Iter 250, loss=0.5086, acc=0.6250\n",
            "2018-12-21 11:53:38 Epoch 1, Iter 300, loss=0.4610, acc=0.6250\n",
            "2018-12-21 11:54:58 Epoch 1, Iter 350, loss=0.2077, acc=0.9167\n",
            "2018-12-21 11:55:27 Epoch 1, train_loss=0.4443, train_accuracy=0.7559\n",
            "2018-12-21 11:57:18 Epoch 1, valid_loss=0.3840, valid_accuracy=0.8374\n",
            "2018-12-21 11:57:28 Epoch 2, Iter 0, loss=0.4770, acc=0.7500\n",
            "2018-12-21 11:58:49 Epoch 2, Iter 50, loss=0.5271, acc=0.7917\n",
            "2018-12-21 12:00:10 Epoch 2, Iter 100, loss=0.2390, acc=0.8333\n",
            "2018-12-21 12:01:31 Epoch 2, Iter 150, loss=0.5051, acc=0.7917\n",
            "2018-12-21 12:02:52 Epoch 2, Iter 200, loss=0.2985, acc=0.8333\n",
            "2018-12-21 12:04:13 Epoch 2, Iter 250, loss=0.6310, acc=0.7083\n",
            "2018-12-21 12:05:34 Epoch 2, Iter 300, loss=0.2175, acc=0.9167\n",
            "2018-12-21 12:06:54 Epoch 2, Iter 350, loss=0.5086, acc=0.5833\n",
            "2018-12-21 12:07:23 Epoch 2, train_loss=0.3722, train_accuracy=0.7930\n",
            "2018-12-21 12:09:15 Epoch 2, valid_loss=0.4068, valid_accuracy=0.8545\n",
            "2018-12-21 12:09:25 Epoch 3, Iter 0, loss=0.5209, acc=0.7083\n",
            "2018-12-21 12:10:47 Epoch 3, Iter 50, loss=0.4145, acc=0.8333\n",
            "2018-12-21 12:12:07 Epoch 3, Iter 100, loss=0.2208, acc=0.9583\n",
            "2018-12-21 12:13:29 Epoch 3, Iter 150, loss=0.2748, acc=0.8333\n",
            "2018-12-21 12:14:49 Epoch 3, Iter 200, loss=0.2712, acc=0.7500\n",
            "2018-12-21 12:16:10 Epoch 3, Iter 250, loss=0.2891, acc=0.7917\n",
            "2018-12-21 12:17:30 Epoch 3, Iter 300, loss=0.6798, acc=0.7083\n",
            "2018-12-21 12:18:51 Epoch 3, Iter 350, loss=0.2450, acc=0.9167\n",
            "2018-12-21 12:19:20 Epoch 3, train_loss=0.3046, train_accuracy=0.8312\n",
            "2018-12-21 12:21:12 Epoch 3, valid_loss=0.3542, valid_accuracy=0.8618\n",
            "2018-12-21 12:21:22 Epoch 4, Iter 0, loss=0.3150, acc=0.7500\n",
            "2018-12-21 12:22:44 Epoch 4, Iter 50, loss=0.2011, acc=0.8750\n",
            "2018-12-21 12:24:06 Epoch 4, Iter 100, loss=0.2366, acc=0.8750\n",
            "2018-12-21 12:25:27 Epoch 4, Iter 150, loss=0.2610, acc=0.7917\n",
            "2018-12-21 12:26:49 Epoch 4, Iter 200, loss=0.2137, acc=0.8333\n",
            "2018-12-21 12:28:09 Epoch 4, Iter 250, loss=0.2784, acc=0.7083\n",
            "2018-12-21 12:29:30 Epoch 4, Iter 300, loss=0.2215, acc=0.8333\n",
            "2018-12-21 12:30:52 Epoch 4, Iter 350, loss=0.1670, acc=0.9583\n",
            "2018-12-21 12:31:21 Epoch 4, train_loss=0.2496, train_accuracy=0.8482\n",
            "2018-12-21 12:33:13 Epoch 4, valid_loss=0.4153, valid_accuracy=0.8587\n",
            "2018-12-21 12:33:15 Epoch 5, Iter 0, loss=0.4319, acc=0.6667\n",
            "2018-12-21 12:34:37 Epoch 5, Iter 50, loss=0.2136, acc=0.8333\n",
            "2018-12-21 12:35:59 Epoch 5, Iter 100, loss=0.2339, acc=0.8333\n",
            "2018-12-21 12:37:19 Epoch 5, Iter 150, loss=0.1796, acc=0.9167\n",
            "2018-12-21 12:38:41 Epoch 5, Iter 200, loss=0.0891, acc=0.9583\n",
            "2018-12-21 12:40:02 Epoch 5, Iter 250, loss=0.1585, acc=0.8333\n",
            "2018-12-21 12:41:23 Epoch 5, Iter 300, loss=0.2440, acc=0.7917\n",
            "2018-12-21 12:42:44 Epoch 5, Iter 350, loss=0.1371, acc=0.9167\n",
            "2018-12-21 12:43:13 Epoch 5, train_loss=0.2130, train_accuracy=0.8638\n",
            "2018-12-21 12:45:05 Epoch 5, valid_loss=0.5921, valid_accuracy=0.8622\n",
            "2018-12-21 12:45:15 Epoch 6, Iter 0, loss=0.1450, acc=0.8333\n",
            "2018-12-21 12:46:37 Epoch 6, Iter 50, loss=0.2035, acc=0.9167\n",
            "2018-12-21 12:47:58 Epoch 6, Iter 100, loss=0.1461, acc=0.9167\n",
            "2018-12-21 12:49:20 Epoch 6, Iter 150, loss=0.2050, acc=0.8333\n",
            "2018-12-21 12:50:41 Epoch 6, Iter 200, loss=0.2397, acc=0.7917\n",
            "2018-12-21 12:52:02 Epoch 6, Iter 250, loss=0.0876, acc=0.9167\n",
            "2018-12-21 12:53:23 Epoch 6, Iter 300, loss=0.2948, acc=0.7083\n",
            "2018-12-21 12:54:44 Epoch 6, Iter 350, loss=0.2071, acc=0.9167\n",
            "2018-12-21 12:55:12 Epoch 6, train_loss=0.1948, train_accuracy=0.8721\n",
            "2018-12-21 12:57:05 Epoch 6, valid_loss=0.4667, valid_accuracy=0.8699\n",
            "2018-12-21 12:57:15 Epoch 7, Iter 0, loss=0.2428, acc=0.8750\n",
            "2018-12-21 12:58:37 Epoch 7, Iter 50, loss=0.1172, acc=0.9167\n",
            "2018-12-21 12:59:58 Epoch 7, Iter 100, loss=0.1462, acc=0.9167\n",
            "2018-12-21 13:01:19 Epoch 7, Iter 150, loss=0.2030, acc=0.7917\n",
            "2018-12-21 13:02:40 Epoch 7, Iter 200, loss=0.1738, acc=0.8750\n",
            "2018-12-21 13:04:01 Epoch 7, Iter 250, loss=0.1168, acc=1.0000\n",
            "2018-12-21 13:05:22 Epoch 7, Iter 300, loss=0.2434, acc=0.8333\n",
            "2018-12-21 13:06:42 Epoch 7, Iter 350, loss=0.1791, acc=0.8333\n",
            "2018-12-21 13:07:10 Epoch 7, train_loss=0.1848, train_accuracy=0.8760\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PyH2SbvbIWxI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 自行添加：/bst_model、/log内文件保存到google drive或本地"
      ]
    },
    {
      "metadata": {
        "id": "1GAoZvBEI_RN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TO DO"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}